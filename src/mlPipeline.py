import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.svm import SVC, LinearSVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import (classification_report, accuracy_score, confusion_matrix, 
                           f1_score, precision_score, recall_score, 
                           balanced_accuracy_score)
from sklearn.utils import class_weight
from imblearn.over_sampling import SMOTE, RandomOverSampler
import matplotlib.pyplot as plt
import seaborn as sns
import time
import warnings
warnings.filterwarnings('ignore')

# Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Ï†Î±ÎºÎ­Î»Î¿Ï… Î³Î¹Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±
import os
os.makedirs('../reports/figures', exist_ok=True)

# --- Î’Î¿Î·Î¸Î·Ï„Î¹ÎºÎ­Ï‚ Î£Ï…Î½Î±ÏÏ„Î®ÏƒÎµÎ¹Ï‚ ---

def load_and_preprocess_data(filepath, target_column, dataset_name=""):
    """
    Î¦Î¿ÏÏ„ÏÎ½ÎµÎ¹ ÎºÎ±Î¹ Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î¬Î¶ÎµÏ„Î±Î¹ Ï„Î± Î´ÎµÎ´Î¿Î¼Î­Î½Î±
    """
    print(f"\n{'='*60}")
    print(f"Î¦ÏŒÏÏ„Ï‰ÏƒÎ· {dataset_name} Î³Î¹Î± Ï€ÏÏŒÎ²Î»ÎµÏˆÎ·: {target_column}")
    print(f"{'='*60}")
    
    try:
        # Î¦ÏŒÏÏ„Ï‰ÏƒÎ· dataset
        df = pd.read_csv(filepath)
        print(f"Î”Î¹Î±ÏƒÏ„Î¬ÏƒÎµÎ¹Ï‚ dataset: {df.shape}")
        
        # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î±Î½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ Î· ÏƒÏ„Î®Î»Î· ÏƒÏ„ÏŒÏ‡Î¿Ï‚
        if target_column not in df.columns:
            print(f"âš ï¸  Î— ÏƒÏ„Î®Î»Î· '{target_column}' Î´ÎµÎ½ Ï…Ï€Î¬ÏÏ‡ÎµÎ¹ ÏƒÏ„Î¿ dataset.")
            return None, None, None, None, None, True
        
        # Î‘Ï†Î±Î¯ÏÎµÏƒÎ· NaN Î±Ï€ÏŒ Ï„Î· ÏƒÏ„Î®Î»Î· ÏƒÏ„ÏŒÏ‡Î¿
        initial_rows = len(df)
        df = df.dropna(subset=[target_column])
        if len(df) < initial_rows:
            print(f"Î‘Ï†Î±Î¹ÏÎ­Î¸Î·ÎºÎ±Î½ {initial_rows - len(df)} Î³ÏÎ±Î¼Î¼Î­Ï‚ Î¼Îµ NaN ÏƒÏ„Î¿ '{target_column}'")
        
        # ÎŸÏÎ¹ÏƒÎ¼ÏŒÏ‚ features ÎºÎ±Î¹ target
        label_columns = ['Label', 'Traffic Type', 'Traffic Subtype']
        feature_columns = [col for col in df.columns if col not in label_columns]
        
        X = df[feature_columns]
        y_raw = df[target_column]
        
        # ÎšÏÎ±Ï„Î¬Î¼Îµ Î¼ÏŒÎ½Î¿ numeric features
        numeric_features = X.select_dtypes(include=[np.number]).columns
        X = X[numeric_features].fillna(0)
        
        print(f"Î‘ÏÎ¹Î¸Î¼ÏŒÏ‚ features: {X.shape[1]}")
        
        # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î³Î¹Î± ÎºÎµÎ½ÏŒ dataset
        if X.empty or len(X) == 0:
            print(f"âŒ ÎšÎµÎ½ÏŒ dataset Î¼ÎµÏ„Î¬ Ï„Î·Î½ Ï€ÏÎ¿ÎµÏ€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î±.")
            return None, None, None, None, None, True
        
        # Label encoding
        le = LabelEncoder()
        y = le.fit_transform(y_raw)
        
        # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Ï€Î»Î·ÏÎ¿Ï†Î¿ÏÎ¹ÏÎ½ Î³Î¹Î± Ï„Î¹Ï‚ ÎºÎ»Î¬ÏƒÎµÎ¹Ï‚
        unique_classes, class_counts = np.unique(y, return_counts=True)
        print(f"\nÎšÎ±Ï„Î±Î½Î¿Î¼Î® ÎºÎ»Î¬ÏƒÎµÏ‰Î½:")
        for i, (cls, count) in enumerate(zip(unique_classes, class_counts)):
            original_label = le.inverse_transform([cls])[0]
            print(f"  {original_label}: {count} Î´ÎµÎ¯Î³Î¼Î±Ï„Î± ({count/len(y)*100:.1f}%)")
        
        # ÎˆÎ»ÎµÎ³Ï‡Î¿Ï‚ Î³Î¹Î± ÎµÏ€Î±ÏÎºÎ® Î±ÏÎ¹Î¸Î¼ÏŒ ÎºÎ»Î¬ÏƒÎµÏ‰Î½
        if len(unique_classes) < 2:
            print(f"âŒ ÎœÏŒÎ½Î¿ {len(unique_classes)} ÎºÎ»Î¬ÏƒÎ· Î²ÏÎ­Î¸Î·ÎºÎµ. Î Î±ÏÎ¬Î»ÎµÎ¹ÏˆÎ·.")
            return None, None, None, None, None, True
        
        # Train-test split Î¼Îµ stratification
        test_size = 0.2
        if len(y) < 100:  # Î“Î¹Î± Ï€Î¿Î»Ï Î¼Î¹ÎºÏÎ¬ datasets
            test_size = 0.3
            
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=y
        )
        
        print(f"\nÎ”Î¹Î±Ï‡Ï‰ÏÎ¹ÏƒÎ¼ÏŒÏ‚ Î´ÎµÎ´Î¿Î¼Î­Î½Ï‰Î½:")
        print(f"  Train: {len(X_train)} Î´ÎµÎ¯Î³Î¼Î±Ï„Î±")
        print(f"  Test: {len(X_test)} Î´ÎµÎ¯Î³Î¼Î±Ï„Î±")
        
        # Scaling
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)
        
        return X_train_scaled, X_test_scaled, y_train, y_test, le, False
        
    except Exception as e:
        print(f"âŒ Î£Ï†Î¬Î»Î¼Î± ÎºÎ±Ï„Î¬ Ï„Î· Ï†ÏŒÏÏ„Ï‰ÏƒÎ·: {str(e)}")
        return None, None, None, None, None, True

def balance_dataset(X_train, y_train, strategy='auto'):
    """
    Î•Î¾Î¹ÏƒÎ¿ÏÏÎ¿Ï€ÎµÎ¯ Ï„Î¿ dataset Î¼Îµ Î´Î¹Î¬Ï†Î¿ÏÎµÏ‚ ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ­Ï‚
    """
    unique_classes, class_counts = np.unique(y_train, return_counts=True)
    
    # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ imbalance ratio
    imbalance_ratio = max(class_counts) / min(class_counts)
    
    if imbalance_ratio < 2:
        print("  âœ“ Î¤Î¿ dataset ÎµÎ¯Î½Î±Î¹ Î®Î´Î· ÏƒÏ‡ÎµÏ„Î¹ÎºÎ¬ Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î·Î¼Î­Î½Î¿")
        return X_train, y_train
    
    print(f"  âš ï¸  Î‘Î½Î¹ÏƒÎ¿ÏÏÎ¿Ï€Î¯Î± {imbalance_ratio:.1f}:1 - Î•Ï†Î±ÏÎ¼Î¿Î³Î® ÎµÎ¾Î¹ÏƒÎ¿ÏÏÏŒÏ€Î·ÏƒÎ·Ï‚...")
    
    # Î•Ï€Î¹Î»Î¿Î³Î® ÏƒÏ„ÏÎ±Ï„Î·Î³Î¹ÎºÎ®Ï‚
    min_class_count = min(class_counts)
    
    if min_class_count < 6:  # Î Î¿Î»Ï Î»Î¯Î³Î± Î´ÎµÎ¯Î³Î¼Î±Ï„Î± Î³Î¹Î± SMOTE
        print(f"  â†’ Î§ÏÎ®ÏƒÎ· RandomOverSampler (min samples: {min_class_count})")
        sampler = RandomOverSampler(random_state=42)
    else:
        try:
            # Î ÏÎ¿ÏƒÏ€Î¬Î¸ÎµÎ¹Î± Î³Î¹Î± SMOTE
            k_neighbors = min(5, min_class_count - 1)
            sampler = SMOTE(random_state=42, k_neighbors=k_neighbors)
            print(f"  â†’ Î§ÏÎ®ÏƒÎ· SMOTE Î¼Îµ k_neighbors={k_neighbors}")
        except:
            # Fallback ÏƒÎµ RandomOverSampler
            print(f"  â†’ Fallback ÏƒÎµ RandomOverSampler")
            sampler = RandomOverSampler(random_state=42)
    
    # Î•Ï†Î±ÏÎ¼Î¿Î³Î® sampling
    X_balanced, y_balanced = sampler.fit_resample(X_train, y_train)
    
    # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Î½Î­Î±Ï‚ ÎºÎ±Ï„Î±Î½Î¿Î¼Î®Ï‚
    new_unique, new_counts = np.unique(y_balanced, return_counts=True)
    print("  ÎÎ­Î± ÎºÎ±Ï„Î±Î½Î¿Î¼Î®:")
    for cls, count in zip(new_unique, new_counts):
        print(f"    ÎšÎ»Î¬ÏƒÎ· {cls}: {count} Î´ÎµÎ¯Î³Î¼Î±Ï„Î±")
    
    return X_balanced, y_balanced

def train_svm_model(X_train, X_test, y_train, y_test, label_encoder=None):
    """
    Î•ÎºÏ€Î±Î¹Î´ÎµÏÎµÎ¹ SVM Î¼Î¿Î½Ï„Î­Î»Î¿
    """
    print("\nğŸ“Š Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· SVM...")
    start_time = time.time()
    
    # Î•Î¾Î¹ÏƒÎ¿ÏÏÏŒÏ€Î·ÏƒÎ· dataset Î±Î½ Ï‡ÏÎµÎ¹Î¬Î¶ÎµÏ„Î±Î¹
    X_train_balanced, y_train_balanced = balance_dataset(X_train, y_train)
    
    # Î•Ï€Î¹Î»Î¿Î³Î® SVM implementation
    if len(X_train_balanced) > 5000:
        print("  â†’ Î§ÏÎ®ÏƒÎ· LinearSVC Î³Î¹Î± Î¼ÎµÎ³Î¬Î»Î¿ dataset")
        model = LinearSVC(random_state=42, max_iter=2000, dual=False)
    else:
        # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ class weights
        classes = np.unique(y_train_balanced)
        weights = class_weight.compute_class_weight('balanced', 
                                                   classes=classes, 
                                                   y=y_train_balanced)
        class_weights = {i: w for i, w in zip(classes, weights)}
        
        # RBF SVM Î¼Îµ probability Î³Î¹Î± Î¼Î¹ÎºÏÎ¬ datasets
        model = SVC(kernel='rbf', random_state=42, 
                   class_weight=class_weights, 
                   probability=True)
    
    # Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·
    model.fit(X_train_balanced, y_train_balanced)
    
    # Î ÏÏŒÎ²Î»ÎµÏˆÎ·
    y_pred = model.predict(X_test)
    
    # Î§ÏÏŒÎ½Î¿Ï‚ ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚
    training_time = time.time() - start_time
    print(f"  âœ“ ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ ÏƒÎµ {training_time:.2f} Î´ÎµÏ…Ï„ÎµÏÏŒÎ»ÎµÏ€Ï„Î±")
    
    return model, y_pred, training_time

def train_mlp_model(X_train, X_test, y_train, y_test, label_encoder=None):
    """
    Î•ÎºÏ€Î±Î¹Î´ÎµÏÎµÎ¹ Neural Network Î¼Î¿Î½Ï„Î­Î»Î¿
    """
    print("\nğŸ§  Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Neural Network...")
    start_time = time.time()
    
    # Î•Î¾Î¹ÏƒÎ¿ÏÏÏŒÏ€Î·ÏƒÎ· dataset
    X_train_balanced, y_train_balanced = balance_dataset(X_train, y_train)
    
    # Î‘ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ® NN Î±Î½Î¬Î»Î¿Î³Î± Î¼Îµ Ï„Î¿ Î¼Î­Î³ÎµÎ¸Î¿Ï‚ Ï„Î¿Ï… dataset
    n_samples = len(X_train_balanced)
    n_features = X_train_balanced.shape[1]
    
    if n_samples < 1000:
        hidden_layers = (50, 25)
        max_iter = 1000
    elif n_samples < 10000:
        hidden_layers = (100, 50)
        max_iter = 500
    else:
        hidden_layers = (200, 100, 50)
        max_iter = 300
    
    print(f"  Î‘ÏÏ‡Î¹Ï„ÎµÎºÏ„Î¿Î½Î¹ÎºÎ®: {n_features} â†’ {' â†’ '.join(map(str, hidden_layers))} â†’ output")
    
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± ÎºÎ±Î¹ ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ· Î¼Î¿Î½Ï„Î­Î»Î¿Ï…
    model = MLPClassifier(
        hidden_layer_sizes=hidden_layers,
        activation='relu',
        solver='adam',
        alpha=0.001,  # L2 regularization
        batch_size='auto',
        learning_rate='adaptive',
        learning_rate_init=0.001,
        max_iter=max_iter,
        early_stopping=True,
        validation_fraction=0.1,
        n_iter_no_change=20,
        random_state=42
    )
    
    # Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·
    model.fit(X_train_balanced, y_train_balanced)
    
    # Î ÏÏŒÎ²Î»ÎµÏˆÎ·
    y_pred = model.predict(X_test)
    
    # Î§ÏÏŒÎ½Î¿Ï‚ ÎµÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚
    training_time = time.time() - start_time
    print(f"  âœ“ ÎŸÎ»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ ÏƒÎµ {training_time:.2f} Î´ÎµÏ…Ï„ÎµÏÏŒÎ»ÎµÏ€Ï„Î±")
    print(f"  Iterations: {model.n_iter_}")
    
    return model, y_pred, training_time

def evaluate_model(y_test, y_pred, label_encoder=None, model_name=""):
    """
    Î‘Î¾Î¹Î¿Î»Î¿Î³ÎµÎ¯ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿ ÎºÎ±Î¹ ÎµÏ€Î¹ÏƒÏ„ÏÎ­Ï†ÎµÎ¹ Î¼ÎµÏ„ÏÎ¹ÎºÎ­Ï‚
    """
    print(f"\nğŸ“ˆ Î‘Î¾Î¹Î¿Î»ÏŒÎ³Î·ÏƒÎ· {model_name}:")
    
    # Î’Î±ÏƒÎ¹ÎºÎ­Ï‚ Î¼ÎµÏ„ÏÎ¹ÎºÎ­Ï‚
    accuracy = accuracy_score(y_test, y_pred)
    balanced_acc = balanced_accuracy_score(y_test, y_pred)
    
    # Î¥Ï€Î¿Î»Î¿Î³Î¹ÏƒÎ¼ÏŒÏ‚ F1 score
    unique_classes = np.unique(y_test)
    if len(unique_classes) == 2:
        # Binary classification
        f1 = f1_score(y_test, y_pred, average='binary', pos_label=1)
        precision = precision_score(y_test, y_pred, average='binary', pos_label=1)
        recall = recall_score(y_test, y_pred, average='binary', pos_label=1)
    else:
        # Multiclass
        f1 = f1_score(y_test, y_pred, average='macro')
        precision = precision_score(y_test, y_pred, average='macro')
        recall = recall_score(y_test, y_pred, average='macro')
    
    # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
    print(f"  â€¢ Accuracy: {accuracy:.4f}")
    print(f"  â€¢ Balanced Accuracy: {balanced_acc:.4f}")
    print(f"  â€¢ F1-Score: {f1:.4f}")
    print(f"  â€¢ Precision: {precision:.4f}")
    print(f"  â€¢ Recall: {recall:.4f}")
    
    # Classification report
    if label_encoder is not None:
        print("\nÎ›ÎµÏ€Ï„Î¿Î¼ÎµÏÎ®Ï‚ Î±Î½Î±Ï†Î¿ÏÎ¬ Î±Î½Î¬ ÎºÎ»Î¬ÏƒÎ·:")
        target_names = [str(label) for label in label_encoder.classes_]
        print(classification_report(y_test, y_pred, 
                                  target_names=target_names,
                                  digits=3))
    
    # Confusion Matrix
    cm = confusion_matrix(y_test, y_pred)
    
    return {
        'accuracy': accuracy,
        'balanced_accuracy': balanced_acc,
        'f1_score': f1,
        'precision': precision,
        'recall': recall,
        'confusion_matrix': cm
    }

def plot_confusion_matrix(cm, labels, title, save_path=None):
    """
    Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ heatmap Î³Î¹Î± confusion matrix
    """
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=labels, yticklabels=labels)
    plt.title(title)
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.close()

def create_results_visualization(results_df):
    """
    Î”Î·Î¼Î¹Î¿Ï…ÏÎ³ÎµÎ¯ ÏƒÏ…Î³ÎºÏÎ¹Ï„Î¹ÎºÎ¬ Î³ÏÎ±Ï†Î®Î¼Î±Ï„Î± Î³Î¹Î± Ï„Î± Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±
    """
    # FIGURE 1: ÎœÎµÏ„ÏÎ¹ÎºÎ­Ï‚ Î‘Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚
    fig1, axes1 = plt.subplots(1, 3, figsize=(18, 6))
    fig1.suptitle('ÎœÎµÏ„ÏÎ¹ÎºÎ­Ï‚ Î‘Ï€ÏŒÎ´Î¿ÏƒÎ·Ï‚ ÎœÎ¿Î½Ï„Î­Î»Ï‰Î½', fontsize=16)
    
    # 1. Accuracy comparison by Dataset
    ax = axes1[0]
    pivot_acc = results_df.pivot_table(index='Dataset', columns='Model', 
                                      values='Accuracy', aggfunc='mean')
    pivot_acc.plot(kind='bar', ax=ax)
    ax.set_title('Accuracy Î±Î½Î¬ Dataset', fontsize=14)
    ax.set_ylabel('Accuracy')
    ax.set_ylim(0, 1.1)
    ax.legend(title='Model')
    ax.grid(axis='y', alpha=0.3)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')
    
    # 2. F1-Score comparison by Dataset
    ax = axes1[1]
    pivot_f1 = results_df.pivot_table(index='Dataset', columns='Model', 
                                     values='F1-Score', aggfunc='mean')
    pivot_f1.plot(kind='bar', ax=ax)
    ax.set_title('F1-Score Î±Î½Î¬ Dataset', fontsize=14)
    ax.set_ylabel('F1-Score')
    ax.set_ylim(0, 1.1)
    ax.legend(title='Model')
    ax.grid(axis='y', alpha=0.3)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')
    
    # 3. Balanced Accuracy comparison
    ax = axes1[2]
    pivot_bal = results_df.pivot_table(index='Dataset', columns='Model', 
                                      values='Balanced Accuracy', aggfunc='mean')
    pivot_bal.plot(kind='bar', ax=ax)
    ax.set_title('Balanced Accuracy Î±Î½Î¬ Dataset', fontsize=14)
    ax.set_ylabel('Balanced Accuracy')
    ax.set_ylim(0, 1.1)
    ax.legend(title='Model')
    ax.grid(axis='y', alpha=0.3)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')
    
    plt.tight_layout()
    plt.savefig('../reports/figures/model_performance_metrics.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    # FIGURE 2: Î£Ï…Î³ÎºÏÎ¹Ï„Î¹ÎºÎ® Î‘Î½Î¬Î»Ï…ÏƒÎ·
    fig2, axes2 = plt.subplots(1, 3, figsize=(18, 6))
    fig2.suptitle('Î£Ï…Î³ÎºÏÎ¹Ï„Î¹ÎºÎ® Î‘Î½Î¬Î»Ï…ÏƒÎ· ÎœÎ¿Î½Ï„Î­Î»Ï‰Î½', fontsize=16)
    
    # 1. Performance by Target
    ax = axes2[0]
    for target in results_df['Target'].unique():
        target_data = results_df[results_df['Target'] == target]
        avg_f1 = target_data.groupby('Model')['F1-Score'].mean()
        x_pos = np.arange(len(avg_f1))
        ax.bar(x_pos + (0.35 if target == 'Label' else -0.35)/2, 
               avg_f1.values, 0.35, label=target)
    ax.set_xticks(np.arange(len(avg_f1)))
    ax.set_xticklabels(avg_f1.index)
    ax.set_title('ÎœÎ­ÏƒÎ· F1-Score Î±Î½Î¬ Target', fontsize=14)
    ax.set_ylabel('F1-Score')
    ax.set_ylim(0, 1.1)
    ax.legend()
    ax.grid(axis='y', alpha=0.3)
    
    # 2. Training Time comparison
    ax = axes2[1]
    pivot_time = results_df.pivot_table(index='Dataset', columns='Model', 
                                       values='Training Time', aggfunc='mean')
    pivot_time.plot(kind='bar', ax=ax, logy=True)
    ax.set_title('Î§ÏÏŒÎ½Î¿Ï‚ Î•ÎºÏ€Î±Î¯Î´ÎµÏ…ÏƒÎ·Ï‚ (log scale)', fontsize=14)
    ax.set_ylabel('Time (seconds)')
    ax.legend(title='Model')
    ax.grid(axis='y', alpha=0.3)
    ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')
    
    # 3. Best Models Summary
    ax = axes2[2]
    best_by_target = results_df.loc[results_df.groupby('Target')['F1-Score'].idxmax()]
    
    y_pos = np.arange(len(best_by_target))
    bars = ax.barh(y_pos, best_by_target['F1-Score'])
    
    # Î§ÏÏ‰Î¼Î±Ï„Î¹ÏƒÎ¼ÏŒÏ‚ Î±Î½Î¬Î»Î¿Î³Î± Î¼Îµ Ï„Î¿ Î¼Î¿Î½Ï„Î­Î»Î¿
    colors = ['#1f77b4' if 'SVM' in model else '#ff7f0e' for model in best_by_target['Model']]
    for bar, color in zip(bars, colors):
        bar.set_color(color)
    
    ax.set_yticks(y_pos)
    ax.set_yticklabels([f"{row['Target']}\n{row['Dataset']}\n{row['Model']}" 
                        for _, row in best_by_target.iterrows()], fontsize=10)
    ax.set_xlabel('F1-Score')
    ax.set_xlim(0, 1.1)
    ax.set_title('ÎšÎ±Î»ÏÏ„ÎµÏÎ± ÎœÎ¿Î½Ï„Î­Î»Î± Î±Î½Î¬ Target', fontsize=14)
    ax.grid(axis='x', alpha=0.3)
    
    # Î ÏÎ¿ÏƒÎ¸Î®ÎºÎ· Ï„Î¹Î¼ÏÎ½ ÏƒÏ„Î¹Ï‚ Î¼Ï€Î¬ÏÎµÏ‚
    for i, (_, row) in enumerate(best_by_target.iterrows()):
        ax.text(row['F1-Score'] + 0.01, i, f"{row['F1-Score']:.3f}", 
                va='center', fontsize=10)
    
    plt.tight_layout()
    plt.savefig('../reports/figures/model_comparison_analysis.png', dpi=300, bbox_inches='tight')
    plt.show()

# --- ÎšÎ¥Î¡Î™Î‘ Î•ÎšÎ¤Î•Î›Î•Î£Î— ---

def main():
    """
    ÎšÏÏÎ¹Î± ÏƒÏ…Î½Î¬ÏÏ„Î·ÏƒÎ· ÎµÎºÏ„Î­Î»ÎµÏƒÎ·Ï‚
    """
    print("="*80)
    print("Î•Î¡Î©Î¤Î—ÎœÎ‘ 3: Î•ÎšÎ Î‘Î™Î”Î•Î¥Î£Î— ÎšÎ‘Î™ Î‘ÎÎ™ÎŸÎ›ÎŸÎ“Î—Î£Î— ÎœÎŸÎÎ¤Î•Î›Î©Î Î¤Î‘ÎÎ™ÎÎŸÎœÎ—Î£Î—Î£")
    print("="*80)
    
    # Datasets Ï€Î¿Ï… Î´Î·Î¼Î¹Î¿Ï…ÏÎ³Î®Î¸Î·ÎºÎ±Î½ ÏƒÏ„Î¿ Î•ÏÏÏ„Î·Î¼Î± 2
    datasets_info = {
        "Balanced_Sampled": "../data/processed/dataset_1_balanced_sampled.csv",
        "KMeans": "../data/processed/dataset_2_kmeans.csv",
        "DBSCAN": "../data/processed/dataset_3_dbscan.csv"
    }
    
    # Î›Î¯ÏƒÏ„Î± Î³Î¹Î± Î±Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
    all_results = []
    
    # Î•Ï€ÎµÎ¾ÎµÏÎ³Î±ÏƒÎ¯Î± ÎºÎ¬Î¸Îµ dataset
    for dataset_name, dataset_path in datasets_info.items():
        print(f"\n{'='*80}")
        print(f"DATASET: {dataset_name}")
        print(f"{'='*80}")
        
        # --- TASK 1: Î ÏÏŒÎ²Î»ÎµÏˆÎ· Label (Benign/Malicious) ---
        print(f"\nğŸ¯ TASK 1: Î ÏÏŒÎ²Î»ÎµÏˆÎ· Label (Benign/Malicious)")
        print("-"*60)
        
        X_train, X_test, y_train, y_test, le_label, skip = load_and_preprocess_data(
            dataset_path, 'Label', dataset_name
        )
        
        if not skip and X_train is not None:
            # SVM
            svm_model, y_pred_svm, svm_time = train_svm_model(
                X_train, X_test, y_train, y_test, le_label
            )
            svm_metrics = evaluate_model(y_test, y_pred_svm, le_label, "SVM")
            
            # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
            all_results.append({
                'Dataset': dataset_name,
                'Target': 'Label',
                'Model': 'SVM',
                'Accuracy': svm_metrics['accuracy'],
                'Balanced Accuracy': svm_metrics['balanced_accuracy'],
                'F1-Score': svm_metrics['f1_score'],
                'Precision': svm_metrics['precision'],
                'Recall': svm_metrics['recall'],
                'Training Time': svm_time
            })
            
            # Neural Network
            mlp_model, y_pred_mlp, mlp_time = train_mlp_model(
                X_train, X_test, y_train, y_test, le_label
            )
            mlp_metrics = evaluate_model(y_test, y_pred_mlp, le_label, "Neural Network")
            
            # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
            all_results.append({
                'Dataset': dataset_name,
                'Target': 'Label',
                'Model': 'Neural Network',
                'Accuracy': mlp_metrics['accuracy'],
                'Balanced Accuracy': mlp_metrics['balanced_accuracy'],
                'F1-Score': mlp_metrics['f1_score'],
                'Precision': mlp_metrics['precision'],
                'Recall': mlp_metrics['recall'],
                'Training Time': mlp_time
            })
            
            # Confusion Matrices
            if le_label is not None:
                labels = le_label.classes_
                plot_confusion_matrix(
                    svm_metrics['confusion_matrix'], 
                    labels,
                    f'Confusion Matrix - {dataset_name} - Label - SVM',
                    f'../reports/figures/cm_{dataset_name}_label_svm.png'
                )
                plot_confusion_matrix(
                    mlp_metrics['confusion_matrix'], 
                    labels,
                    f'Confusion Matrix - {dataset_name} - Label - MLP',
                    f'../reports/figures/cm_{dataset_name}_label_mlp.png'
                )
        
        # --- TASK 2: Î ÏÏŒÎ²Î»ÎµÏˆÎ· Traffic Type ---
        print(f"\nğŸ¯ TASK 2: Î ÏÏŒÎ²Î»ÎµÏˆÎ· Traffic Type")
        print("-"*60)
        
        X_train, X_test, y_train, y_test, le_traffic, skip = load_and_preprocess_data(
            dataset_path, 'Traffic Type', dataset_name
        )
        
        if not skip and X_train is not None:
            # SVM
            svm_model, y_pred_svm, svm_time = train_svm_model(
                X_train, X_test, y_train, y_test, le_traffic
            )
            svm_metrics = evaluate_model(y_test, y_pred_svm, le_traffic, "SVM")
            
            # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
            all_results.append({
                'Dataset': dataset_name,
                'Target': 'Traffic Type',
                'Model': 'SVM',
                'Accuracy': svm_metrics['accuracy'],
                'Balanced Accuracy': svm_metrics['balanced_accuracy'],
                'F1-Score': svm_metrics['f1_score'],
                'Precision': svm_metrics['precision'],
                'Recall': svm_metrics['recall'],
                'Training Time': svm_time
            })
            
            # Neural Network
            mlp_model, y_pred_mlp, mlp_time = train_mlp_model(
                X_train, X_test, y_train, y_test, le_traffic
            )
            mlp_metrics = evaluate_model(y_test, y_pred_mlp, le_traffic, "Neural Network")
            
            # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
            all_results.append({
                'Dataset': dataset_name,
                'Target': 'Traffic Type',
                'Model': 'Neural Network',
                'Accuracy': mlp_metrics['accuracy'],
                'Balanced Accuracy': mlp_metrics['balanced_accuracy'],
                'F1-Score': mlp_metrics['f1_score'],
                'Precision': mlp_metrics['precision'],
                'Recall': mlp_metrics['recall'],
                'Training Time': mlp_time
            })
    
    # --- Î£Î¥ÎÎŸÎ¨Î— Î‘Î ÎŸÎ¤Î•Î›Î•Î£ÎœÎ‘Î¤Î©Î ---
    print(f"\n{'='*80}")
    print("Î£Î¥ÎÎŸÎ¨Î— Î‘Î ÎŸÎ¤Î•Î›Î•Î£ÎœÎ‘Î¤Î©Î")
    print(f"{'='*80}")
    
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± DataFrame Î¼Îµ Î±Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î±
    results_df = pd.DataFrame(all_results)
    
    # Î•Î¼Ï†Î¬Î½Î¹ÏƒÎ· Ï€Î¯Î½Î±ÎºÎ± Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½
    print("\nğŸ“Š Î Î¯Î½Î±ÎºÎ±Ï‚ Î‘Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½:")
    print(results_df.to_string(index=False, float_format='%.4f'))
    
    # Î‘Ï€Î¿Î¸Î®ÎºÎµÏ…ÏƒÎ· Î±Ï€Î¿Ï„ÎµÎ»ÎµÏƒÎ¼Î¬Ï„Ï‰Î½ ÏƒÎµ CSV
    results_df.to_csv('../reports/model_results.csv', index=False)
    print("\nâœ… Î‘Ï€Î¿Ï„ÎµÎ»Î­ÏƒÎ¼Î±Ï„Î± Î±Ï€Î¿Î¸Î·ÎºÎµÏÏ„Î·ÎºÎ±Î½ ÏƒÏ„Î¿: ../reports/model_results.csv")
    
    # --- Î‘ÎÎ‘Î›Î¥Î£Î— ÎšÎ‘Î›Î¥Î¤Î•Î¡Î©Î ÎœÎŸÎÎ¤Î•Î›Î©Î ---
    print(f"\n{'='*80}")
    print("Î‘ÎÎ‘Î›Î¥Î£Î— ÎšÎ‘Î›Î¥Î¤Î•Î¡Î©Î ÎœÎŸÎÎ¤Î•Î›Î©Î")
    print(f"{'='*80}")
    
    # ÎšÎ±Î»ÏÏ„ÎµÏÎ¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Î³Î¹Î± Label prediction
    label_results = results_df[results_df['Target'] == 'Label']
    if not label_results.empty:
        best_label_idx = label_results['F1-Score'].idxmax()
        best_label = label_results.loc[best_label_idx]
        
        print(f"\nğŸ† ÎšÎ±Î»ÏÏ„ÎµÏÎ¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Î³Î¹Î± Ï€ÏÏŒÎ²Î»ÎµÏˆÎ· Label (Benign/Malicious):")
        print(f"   â€¢ Dataset: {best_label['Dataset']}")
        print(f"   â€¢ Model: {best_label['Model']}")
        print(f"   â€¢ F1-Score: {best_label['F1-Score']:.4f}")
        print(f"   â€¢ Balanced Accuracy: {best_label['Balanced Accuracy']:.4f}")
        print(f"   â€¢ Training Time: {best_label['Training Time']:.2f}s")
    
    # ÎšÎ±Î»ÏÏ„ÎµÏÎ¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Î³Î¹Î± Traffic Type prediction
    traffic_results = results_df[results_df['Target'] == 'Traffic Type']
    if not traffic_results.empty:
        best_traffic_idx = traffic_results['F1-Score'].idxmax()
        best_traffic = traffic_results.loc[best_traffic_idx]
        
        print(f"\nğŸ† ÎšÎ±Î»ÏÏ„ÎµÏÎ¿ Î¼Î¿Î½Ï„Î­Î»Î¿ Î³Î¹Î± Ï€ÏÏŒÎ²Î»ÎµÏˆÎ· Traffic Type:")
        print(f"   â€¢ Dataset: {best_traffic['Dataset']}")
        print(f"   â€¢ Model: {best_traffic['Model']}")
        print(f"   â€¢ F1-Score: {best_traffic['F1-Score']:.4f}")
        print(f"   â€¢ Balanced Accuracy: {best_traffic['Balanced Accuracy']:.4f}")
        print(f"   â€¢ Training Time: {best_traffic['Training Time']:.2f}s")
    
    # --- Î£Î¥Î“ÎšÎ¡Î™Î¤Î™ÎšÎ— Î‘ÎÎ‘Î›Î¥Î£Î— ---
    print(f"\n{'='*80}")
    print("Î£Î¥Î“ÎšÎ¡Î™Î¤Î™ÎšÎ— Î‘ÎÎ‘Î›Î¥Î£Î—")
    print(f"{'='*80}")
    
    # ÎœÎ­ÏƒÎ¿Î¹ ÏŒÏÎ¿Î¹ Î±Î½Î¬ Î¼Î¿Î½Ï„Î­Î»Î¿
    print("\nğŸ“Š ÎœÎ­ÏƒÎ· Î±Ï€ÏŒÎ´Î¿ÏƒÎ· Î±Î½Î¬ Î¼Î¿Î½Ï„Î­Î»Î¿:")
    model_avg = results_df.groupby('Model')[['F1-Score', 'Balanced Accuracy']].mean()
    print(model_avg.round(4))
    
    # ÎœÎ­ÏƒÎ¿Î¹ ÏŒÏÎ¿Î¹ Î±Î½Î¬ dataset
    print("\nğŸ“Š ÎœÎ­ÏƒÎ· Î±Ï€ÏŒÎ´Î¿ÏƒÎ· Î±Î½Î¬ dataset:")
    dataset_avg = results_df.groupby('Dataset')[['F1-Score', 'Balanced Accuracy']].mean()
    print(dataset_avg.round(4))
    
    # ÎœÎ­ÏƒÎ¿Î¹ ÏŒÏÎ¿Î¹ Î±Î½Î¬ target
    print("\nğŸ“Š ÎœÎ­ÏƒÎ· Î±Ï€ÏŒÎ´Î¿ÏƒÎ· Î±Î½Î¬ target:")
    target_avg = results_df.groupby('Target')[['F1-Score', 'Balanced Accuracy']].mean()
    print(target_avg.round(4))
    
    # Î”Î·Î¼Î¹Î¿Ï…ÏÎ³Î¯Î± Î³ÏÎ±Ï†Î·Î¼Î¬Ï„Ï‰Î½
    create_results_visualization(results_df)
    
    print("\nâœ… Î— Î±Î½Î¬Î»Ï…ÏƒÎ· Î¿Î»Î¿ÎºÎ»Î·ÏÏÎ¸Î·ÎºÎµ ÎµÏ€Î¹Ï„Ï…Ï‡ÏÏ‚!")

if __name__ == "__main__":
    main()